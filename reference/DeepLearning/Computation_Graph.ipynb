{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensors and Computation Graphs\n",
    "\n",
    "[TOC]\n",
    "\n",
    "TensorFlow uses a dataflow graph to represent your computation in terms of the dependencies between individual operations. This leads to a low-level programming model in which you first define the dataflow graph, then create a TensorFlow session to run parts of the graph across a set of local and remote devices.\n",
    "\n",
    "## 1. How Does TensorFlow Work\n",
    "\n",
    "You might think of TensorFlow Core programs as consisting of two discrete sections:\n",
    "* Building the computational graph (tf.Graph).\n",
    "* Running the computational graph (tf.Session).\n",
    "\n",
    "### 1.1. Graph\n",
    "\n",
    "A computation graph is a series of TensorFlow operations arranged into a graph. The graph is composed of two types of objects.\n",
    "\n",
    "* tf.Operation (or \"ops\"): The nodes of the graph. Operations describe calculations that consume and produce tensors.\n",
    "\n",
    "* tf.Tensor: The edges in the graph. These represent the values that will flow through the graph. Most TensorFlow functions return tf.Tensors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_12:0\", shape=(), dtype=float32)\n",
      "Tensor(\"Const_13:0\", shape=(), dtype=float32)\n",
      "Tensor(\"add_6:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant(3.0, dtype=tf.float32)\n",
    "b = tf.constant(4.0, dtype=tf.float32)\n",
    "total = a + b\n",
    "print(a)\n",
    "print(b)\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** tf.Tensors do not have values, they are just handles to elements in the computation graph. \n",
    "\n",
    "We will go back to discuss how to build the computational graph later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Session\n",
    "\n",
    "To evaluate tensors, instantiate a tf.Session object, informally known as a session. A session encapsulates the state of the TensorFlow runtime, and runs TensorFlow operations. * If a tf.Graph is like a .py file, a tf.Session is like the python executable.*\n",
    "\n",
    "The following code creates a tf.Session object and then invokes its run method to evaluate the total tensor we created above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n",
      "4.0\n",
      "7.0\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "print(sess.run(a))\n",
    "print(sess.run(b))\n",
    "print(sess.run(total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Graph Visualization\n",
    "\n",
    "TensorFlow provides a utility called TensorBoard. One of TensorBoard's many capabilities is visualizing a computation graph. You can easily do this with a few simple commands.\n",
    "\n",
    "First you save the computation graph to a TensorBoard summary file as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = tf.summary.FileWriter('.')\n",
    "writer.add_graph(tf.get_default_graph())\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will produce an event file in the current directory with a name in the following format:\n",
    "**events.out.tfevents.{timestamp}.{hostname}**\n",
    "\n",
    "Now, in a new terminal, launch TensorBoard with the following shell command:\n",
    "**tensorboard --logdir .**\n",
    "\n",
    "Then open TensorBoard's [graphs page](http://localhost:6006/#graphs) in your browser, and you should see a graph.\n",
    "\n",
    "For more about TensorBoard's graph visualization tools see [TensorBoard: Graph Visualization](https://www.tensorflow.org/guide/graph_viz).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Tensors\n",
    "\n",
    "A Tensor is a symbolic **handle** to one of the outputs of an Operation. It does not hold the values of that operation's output, but instead provides a means of computing those values in a TensorFlow tf.Session.\n",
    "\n",
    "This class has two primary purposes:\n",
    "\n",
    "* A Tensor can be passed as an input to another Operation. This builds a dataflow connection between operations, which enables TensorFlow to execute an entire Graph that represents a large, multi-step computation. *That is, it is an edge in the computation graph.*\n",
    "\n",
    "* After the graph has been launched in a session, the value of the Tensor can be computed by passing it to tf.Session.run. t.eval() is a shortcut for calling tf.get_default_session().run(t).\n",
    "\n",
    "A tf.Tensor has the following properties:\n",
    "\n",
    "* A data type (float32, int32, or string, for example). Each element in the Tensor has the same data type, and the data type is always known.\n",
    "\n",
    "* A shape. The shape (that is, the number of dimensions it has and the size of each dimension) might be only partially known. Most operations produce tensors of fully-known shapes if the shapes of their inputs are also fully known, but in some cases it's only possible to find the shape of a tensor at graph execution time.\n",
    "\n",
    "* An Operation. Operation that computes this tensor.\n",
    "\n",
    "The main tensors include:\n",
    "* tf.Variable\n",
    "* tf.constant\n",
    "* tf.placeholder\n",
    "* tf.SparseTensor\n",
    "\n",
    "With the exception of tf.Variable, the value of a tensor is immutable, which means that in the context of a single execution tensors only have a single value. However, evaluating the same tensor twice can return different values; for example that tensor can be the result of reading data from disk, or generating a random number.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_23:0\", shape=(3,), dtype=float32)\n",
      "<tf.Variable 'Variable_1:0' shape=(3,) dtype=float32_ref>\n",
      "Tensor(\"add_18:0\", shape=(3,), dtype=float32)\n",
      "name: \"add_18\"\n",
      "op: \"Add\"\n",
      "input: \"Const_23\"\n",
      "input: \"Variable_1/read\"\n",
      "attr {\n",
      "  key: \"T\"\n",
      "  value {\n",
      "    type: DT_FLOAT\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "c = tf.constant([1.0,2,3], dtype=tf.float32)\n",
    "d = tf.Variable([4,5,6.0], dtype=tf.float32)\n",
    "total = c + d\n",
    "\n",
    "print(c)\n",
    "print(d)\n",
    "print(total)\n",
    "print(total.op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Transformation between Tensors and Numpy Arrays \n",
    "\n",
    "Once the computation graph has been built, you can run the computation that produces a particular tf.Tensor and fetch the value assigned to it. This is often useful for debugging as well as being required for much of TensorFlow to work.\n",
    "\n",
    "* The simplest way to evaluate a Tensor is using the Tensor.eval method. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 4 9]\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "constant = tf.constant([1, 2, 3])\n",
    "tensor = constant * constant\n",
    "sess = tf.Session()\n",
    "## Transform a tensor into a numpy array\n",
    "fetch_value = tensor.eval(session=sess)\n",
    "print(fetch_value)\n",
    "print(type(tensor))\n",
    "print(type(fetch_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* One can then use tf.convert_to_tensor to transform a numpy array into tensor. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const_35:0\", shape=(3,), dtype=int32)\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "## Transform a numpy array into a tensor\n",
    "trans_tensor = tf.convert_to_tensor(fetch_value)\n",
    "print(trans_tensor)\n",
    "print(type(trans_tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Building a tf.Graph\n",
    "\n",
    "Most TensorFlow programs start with a computation graph construction phase. In this phase, you invoke TensorFlow API functions that construct new tf.Operation (node) and tf.Tensor (edge) objects and add them to a tf.Graph instance. TensorFlow provides a default graph that is an implicit argument to all API functions in the same context. For example:\n",
    "\n",
    "* Calling tf.constant(42.0) creates a single tf.Operation that produces the value 42.0, adds it to the default graph, and returns a tf.Tensor that represents the value of the constant.\n",
    "\n",
    "* Calling tf.matmul(x, y) creates a single tf.Operation that multiplies the values of tf.Tensor objects x and y, adds it to the default graph, and returns a tf.Tensor that represents the result of the multiplication.\n",
    "\n",
    "* Executing v = tf.Variable(0) adds to the graph a tf.Operation that will store a writeable tensor value that persists between tf.Session.run calls. The tf.Variable object wraps this operation, and can be used like a tensor, which will read the current value of the stored value. The tf.Variable object also has methods such as tf.Variable.assign and tf.Variable.assign_add that create tf.Operation objects that, when executed, update the stored value.\n",
    "\n",
    "* Calling tf.train.Optimizer.minimize will add operations and tensors to the default graph that calculates gradients, and return a tf.Operation that, when run, will apply those gradients to a set of variables.\n",
    "\n",
    "\n",
    "In the following, we present some examples to how to build the computation graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. A simple example: computing a=(b+c)∗(c+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"a:0\", shape=(), dtype=float32)\n",
      "9.0\n"
     ]
    }
   ],
   "source": [
    "const = tf.constant(2.0, name='const')\n",
    "\n",
    "b = tf.Variable(2.0, name='b')\n",
    "c = tf.Variable(1.0, dtype=tf.float32, name='c')\n",
    "d = tf.add(b, c, name='d')\n",
    "e = tf.add(c, const, name='e')\n",
    "a = tf.multiply(d, e, name='a')\n",
    "print(a)\n",
    "\n",
    "sess = tf.Session()\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess.run(init_op)\n",
    "a_out = sess.run(a)\n",
    "print(a_out)\n",
    "\n",
    "writer = tf.summary.FileWriter('.')\n",
    "writer.add_graph(tf.get_default_graph())\n",
    "writer.flush()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Matrix Multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A is [1. 2. 3.]\n",
      "B is [[1. 2. 3.]]\n",
      "C is [[1. 2. 3.]\n",
      " [2. 4. 6.]\n",
      " [3. 6. 9.]]\n",
      "D is [[-1.0206345  -1.9120213   0.45873082]]\n",
      "E is [[13.323662 28.117954 45.0393  ]]\n"
     ]
    }
   ],
   "source": [
    "A = tf.constant([1,2,3],dtype=tf.float32)\n",
    "B = tf.Variable(tf.zeros([1,3])) + A\n",
    "C = tf.Variable([[1,2,3],[2,4,6],[3,6,9]],dtype=tf.float32)\n",
    "D = tf.random_normal([1,3])\n",
    "\n",
    "E = tf.matmul(B,C) + D\n",
    "\n",
    "sess = tf.Session()\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess.run(init_op)\n",
    "print(\"A is {}\".format(sess.run(A)))\n",
    "print(\"B is {}\".format(sess.run(B)))\n",
    "print(\"C is {}\".format(sess.run(C)))\n",
    "print(\"D is {}\".format(sess.run(D)))\n",
    "print(\"E is {}\".format(sess.run(E)))\n",
    "\n",
    "writer = tf.summary.FileWriter('.')\n",
    "writer.add_graph(tf.get_default_graph())\n",
    "writer.flush()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Placeholder\n",
    "\n",
    "A graph can be parameterized to accept external inputs, known as placeholders. A placeholder is a promise to provide a value later, like a function argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable a is [[0.1]\n",
      " [1.1]\n",
      " [2.1]\n",
      " [3.1]\n",
      " [4.1]\n",
      " [5.1]\n",
      " [6.1]\n",
      " [7.1]\n",
      " [8.1]\n",
      " [9.1]]\n"
     ]
    }
   ],
   "source": [
    "input = tf.placeholder(tf.float32, [None, 1], name='input')\n",
    "res = input + 0.1;\n",
    "\n",
    "sess = tf.Session()\n",
    "output = sess.run(res, feed_dict={input: np.arange(0, 10)[:, np.newaxis]})\n",
    "print(\"Variable a is {}\".format(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = tf.summary.FileWriter('.')\n",
    "writer.add_graph(tf.get_default_graph())\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. A Neural Network Example**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "Epoch: 1 cost =  0.742\n",
      "Epoch: 2 cost =  0.263\n",
      "Epoch: 3 cost =  0.194\n",
      "Epoch: 4 cost =  0.159\n",
      "Epoch: 5 cost =  0.134\n",
      "Epoch: 6 cost =  0.114\n",
      "Epoch: 7 cost =  0.100\n",
      "Epoch: 8 cost =  0.085\n",
      "Epoch: 9 cost =  0.074\n",
      "Epoch: 10 cost =  0.067\n",
      "0.975\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "# Define parameters\n",
    "learning_rate = 0.5\n",
    "epochs = 10\n",
    "batch_size = 100\n",
    "\n",
    "# Placeholder\n",
    "# The size of the input image is 28 x 28 = 784\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "# The output size is 0-9 one-hot label\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# hidden layer => w1, b1\n",
    "W1 = tf.Variable(tf.random_normal([784, 300], stddev=0.03), name='W1')\n",
    "b1 = tf.Variable(tf.random_normal([300]), name='b1')\n",
    "hidden_out = tf.add(tf.matmul(x, W1), b1)\n",
    "hidden_out = tf.nn.relu(hidden_out)\n",
    "\n",
    "# output layer => w, b\n",
    "W2 = tf.Variable(tf.random_normal([300, 10], stddev=0.03), name='W2')\n",
    "b2 = tf.Variable(tf.random_normal([10]), name='b2')\n",
    "y_ = tf.nn.softmax(tf.add(tf.matmul(hidden_out, W2), b2))\n",
    "\n",
    "# Define the loss function\n",
    "y_clipped = tf.clip_by_value(y_, 1e-10, 0.9999999)\n",
    "cross_entropy = -tf.reduce_mean(tf.reduce_sum(y * tf.log(y_clipped) + (1 - y) * tf.log(1 - y_clipped), axis=1))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cross_entropy)\n",
    "\n",
    "# Define the accuracy function\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# Define init operator\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Initialize the varaibles\n",
    "    sess.run(init)\n",
    "    total_batch = int(len(mnist.train.labels) / batch_size)\n",
    "    for epoch in range(epochs):\n",
    "        avg_cost = 0\n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size=batch_size)\n",
    "            _, c = sess.run([optimizer, cross_entropy], feed_dict={x: batch_x, y: batch_y})\n",
    "            avg_cost += c / total_batch\n",
    "        print(\"Epoch:\", (epoch + 1), \"cost = \", \"{:.3f}\".format(avg_cost))\n",
    "    print(sess.run(accuracy, feed_dict={x: mnist.test.images, y: mnist.test.labels}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: \n",
    "\n",
    "* tf.clip_by_value(A, min, max)：for the input tensor A，transform each element of A into the range between min and max.\n",
    "* reduce_sum Compute the sum of elements across the indicated dimensions of the input tensor.\n",
    "* reduce_mean Compute the mean of elements across the indicated dimensions of the input tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = tf.summary.FileWriter('.')\n",
    "writer.add_graph(tf.get_default_graph())\n",
    "writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Graph Execution\n",
    "\n",
    "### 4.1. Single-Device Execution\n",
    "\n",
    "Let’s first consider the simplest execution scenario: a single worker process with a single device. The nodes of the graph are executed in an order that respects the dependencies between nodes (a topological ordering). In particular, we keep track of a count per node of the number of dependencies of that node that have not yet been executed. Once this count drops to zero, the node is eligible for execution and is added to a ready queue. The ready queue is processed in some unspecified order, delegating execution of the kernel for a node to the device object. When a node has finished executing, the counts of all nodes that depend on the completed node are decremented.\n",
    "\n",
    "Note that the formed computation graph is a directed acyclic graph (DAG), and the in-degree of each node is the number of dependencies of that node that have not yet been executed. The Graph Execution algorithm can be discribed as follows:\n",
    "\n",
    "1. Initiate an array to count the in-degree of each node in the computation graph. \n",
    "\n",
    "2. Initiate a queue, and push all nodes with zero in-degree into the queue.\n",
    "\n",
    "3. While the queue is not empty, pop one node to excute, remove this node from the graph.\n",
    "\n",
    "4. Decrease by 1 the in-degree of all nodes that depend on this excuted node. When those node's in-degrees become zero, push them into the queue.\n",
    "\n",
    "5. Repeat Steps 3-4 until the queue become empty.\n",
    "\n",
    "\n",
    "### 4.2. Multi-Device Execution\n",
    "\n",
    "Once a system has multiple devices, there are two main complications: \n",
    "* Deciding which device to place the computation for each node in the graph;\n",
    "* Managing the required communication of data across device boundaries implied by these placement decisions. \n",
    "\n",
    "One can refer to the White Paper of TensorFlwo for more detail about the Multi-Device Execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
