{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[4,2], name='x')\n",
    "y = tf.placeholder(tf.float32, shape=[4,1], name='y')\n",
    "\n",
    "XOR_X = [[0,0],[0,1],[1,0],[1,1]]\n",
    "XOR_Y = [[0],[1],[1],[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用设定好的weight和bias，参考DL_Chapter.6_Page.179"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XOR problem:  mse=0.0, y prediction: \n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "# 1. with no parameters\n",
    "with tf.variable_scope(\"hidden_layer\") as scope:\n",
    "    w = tf.constant([[1., 1.],[1., 1.]], shape=[2, 2])\n",
    "    b = tf.constant([0., -1.], shape=[2,])\n",
    "    x_ = tf.nn.relu(tf.add(tf.matmul(x, w), b))\n",
    "\n",
    "with tf.variable_scope(\"output\") as scope:\n",
    "    w = tf.constant([[1.], [-2.]], shape=[2, 1])\n",
    "    b = tf.constant([0.], shape=[1,])\n",
    "    y_ = tf.add(tf.matmul(x_, w), b)\n",
    "    \n",
    "loss = tf.reduce_mean(tf.square(y - y_))\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    pred, l = sess.run([y_, loss], feed_dict={x: XOR_X, y: XOR_Y})\n",
    "    print(f\"XOR problem:  mse={l}, y prediction: \\n{pred}\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## use neural network to optimize paramters\n",
    "Extend the width of hidden layer to 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:0 -> Loss:1.0331549644470215 -> Predictions \n",
      "[[0.8677178]\n",
      " [0.8495208]\n",
      " [0.8399066]\n",
      " [0.8300507]]\n",
      "Step:2000 -> Loss:0.0007946743862703443 -> Predictions \n",
      "[[2.5990605e-04]\n",
      " [9.9867189e-01]\n",
      " [9.9867195e-01]\n",
      " [2.6088953e-04]]\n",
      "Step:4000 -> Loss:0.0004948877030983567 -> Predictions \n",
      "[[1.5562773e-04]\n",
      " [9.9916565e-01]\n",
      " [9.9916565e-01]\n",
      " [1.5461445e-04]]\n",
      "Step:6000 -> Loss:0.00046294950880110264 -> Predictions \n",
      "[[1.4480948e-04]\n",
      " [9.9921876e-01]\n",
      " [9.9921876e-01]\n",
      " [1.4382601e-04]]\n",
      "Step:8000 -> Loss:0.00045987218618392944 -> Predictions \n",
      "[[1.4385581e-04]\n",
      " [9.9922395e-01]\n",
      " [9.9922395e-01]\n",
      " [1.4287233e-04]]\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope(\"layer1\", reuse=tf.AUTO_REUSE) as scope:\n",
    "    w1 = tf.get_variable('w1', shape=[2, 3])\n",
    "    b1 = tf.get_variable('b1', shape=[3,])\n",
    "    x1 = tf.nn.relu(tf.add(tf.matmul(x, w1), b1))\n",
    "\n",
    "with tf.variable_scope(\"layer2\", reuse=tf.AUTO_REUSE) as scope:\n",
    "    w2 = tf.get_variable('w2', shape=[3, 1])\n",
    "    b2 = tf.get_variable('b2', shape=[1,])\n",
    "    x2 = tf.add(tf.matmul(x1, w2), b2)\n",
    "   \n",
    "preds = tf.nn.sigmoid(x2)\n",
    "init = tf.global_variables_initializer()\n",
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels=y, logits=x2))\n",
    "\n",
    "# define optimizer\n",
    "learning_rate = tf.placeholder(tf.float32)\n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    writer = tf.summary.FileWriter(\"./logs/xor_logs\", sess.graph)\n",
    "    sess.run(init)    \n",
    "\n",
    "    for step in range(10000):\n",
    "        if step < 3000:\n",
    "            lr = 1\n",
    "        elif step < 6000:\n",
    "            lr = 0.1\n",
    "        else:\n",
    "            lr = 0.01\n",
    "        _, pred, l = sess.run([train_step, preds, loss], feed_dict={x: XOR_X, y: XOR_Y, learning_rate: lr})\n",
    "        if not step % 2000:\n",
    "            print('Step:{} -> Loss:{} -> Predictions \\n{}'.format(step, l, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter_36",
   "language": "python",
   "name": "jupyter_36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
